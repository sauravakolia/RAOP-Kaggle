{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Saurav\n",
      "[nltk_data]     Akolia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using naive bayes\n",
      "0.474009900990099\n",
      "Using LOgistic Regression\n",
      "0.7363861386138614\n",
      "Using SVM\n",
      "0.474009900990099\n"
     ]
    }
   ],
   "source": [
    "#USING request_title as Features Dataset\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import sklearn.ensemble \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.feature_extraction.text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.naive_bayes\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import nltk.corpus\n",
    "import nltk.stem.porter\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "f=open('C:\\\\Users\\\\Saurav Akolia\\\\Desktop\\\\MLfiles\\\\FreePizaa\\\\train.json')\n",
    "data=f.read()\n",
    "data=json.loads(data)\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "poter_stemmer=nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "stopWords=set(nltk.corpus.stopwords.words('english'))\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "\n",
    "trainData=df['request_title']\n",
    "\n",
    "def stemmed_words(trainData):\n",
    "  return (poter_stemmer.stem(w) for w in analyzer(trainData))\n",
    "\n",
    "\n",
    "\n",
    "vect=CountVectorizer(stop_words=stopWords,analyzer=stemmed_words)\n",
    "tf_train=vect.fit_transform(trainData)\n",
    "x=(tf_train.toarray())\n",
    "\n",
    "\n",
    "\n",
    "y=df['requester_received_pizza']\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "#USING Naive_Bayes\n",
    "\n",
    "print('Using naive bayes')\n",
    "model=sklearn.naive_bayes.GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "\n",
    "x1=pd.DataFrame(x)\n",
    "\n",
    "y1=pd.Categorical(df['requester_received_pizza']).codes\n",
    "y1=pd.DataFrame(y1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Using LOgistic Regression')\n",
    "regl=sklearn.linear_model.LogisticRegression()\n",
    "regl.fit(x_train,y_train)\n",
    "print(regl.score(x_test,y_test))\n",
    "\n",
    "\n",
    "print('Using SVM')\n",
    "modelsvm=sklearn.svm.SVC(kernel='poly')\n",
    "modelsvm.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive_bayes\n",
      "0.4591584158415842\n",
      "Using LOgistic Regression\n",
      "0.6856435643564357\n",
      "Using SVM\n",
      "0.4591584158415842\n"
     ]
    }
   ],
   "source": [
    "# Using request_text\n",
    "\n",
    "\n",
    "f=open('C:\\\\Users\\\\Saurav Akolia\\\\Desktop\\\\MLfiles\\\\FreePizaa\\\\train.json')\n",
    "data=f.read()\n",
    "data=json.loads(data)\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "poter_stemmer=nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "stopWords=set(nltk.corpus.stopwords.words('english'))\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "\n",
    "trainData=df['request_text_edit_aware']\n",
    "\n",
    "def stemmed_words(trainData):\n",
    "  return (poter_stemmer.stem(w) for w in analyzer(trainData))\n",
    "\n",
    "\n",
    "\n",
    "vect=CountVectorizer(stop_words=stopWords,analyzer=stemmed_words)\n",
    "tf_train=vect.fit_transform(trainData)\n",
    "\n",
    "x=(tf_train.toarray())\n",
    "y=df['requester_received_pizza']\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "#USING naive bayes\n",
    "\n",
    "print('Using Naive_bayes')\n",
    "model=sklearn.naive_bayes.GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "\n",
    "x1=pd.DataFrame(x)\n",
    "\n",
    "y1=pd.Categorical(df['requester_received_pizza']).codes\n",
    "y1=pd.DataFrame(y1)\n",
    "\n",
    "\n",
    "\n",
    "print('Using LOgistic Regression')\n",
    "regl=sklearn.linear_model.LogisticRegression()\n",
    "regl.fit(x_train,y_train)\n",
    "print(regl.score(x_test,y_test))\n",
    "\n",
    "\n",
    "\n",
    "print('Using SVM')\n",
    "modelsvm=sklearn.svm.SVC(kernel='poly')\n",
    "modelsvm.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING Random Forest\n",
      "0.8527227722772277\n",
      "USING Logistic Regression\n",
      "0.7574257425742574\n",
      "USING naive Bayes\n",
      "0.7512376237623762\n",
      "Using SVM\n",
      "0.7512376237623762\n"
     ]
    }
   ],
   "source": [
    "#USING numerical_data\n",
    "\n",
    "f=open('C:\\\\Users\\\\Saurav Akolia\\\\Desktop\\\\MLfiles\\\\FreePizaa\\\\train.json')\n",
    "data=f.read()\n",
    "data=json.loads(data)\n",
    "c=0\n",
    "a=[]\n",
    "b=[]\n",
    "\n",
    "for x in data:\n",
    "\t\n",
    "\tdel x['request_text']\n",
    "\tdel x['request_text_edit_aware']\n",
    "\tdel x['request_title']\n",
    "\tdel x['requester_subreddits_at_request']\n",
    "\tdel x['requester_username']\n",
    "\tdel x['giver_username_if_known']\n",
    "\tdel x['request_id']\n",
    "\tdel x['requester_user_flair']\n",
    "\n",
    "\tdel x['requester_days_since_first_post_on_raop_at_request']\n",
    "\tdel x['requester_days_since_first_post_on_raop_at_retrieval']\n",
    "\tdel x['requester_number_of_posts_on_raop_at_request']\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data)\t\t\n",
    "\n",
    "y=df['requester_received_pizza']\n",
    "df=df.drop(['requester_received_pizza'],axis=1)\n",
    "x=df\n",
    "\n",
    "#USing Random Forest\n",
    "\n",
    "print('USING Random Forest')\n",
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clfr=sklearn.ensemble.RandomForestClassifier(random_state=0)\n",
    "clfr.fit(x_train,y_train)\n",
    "\n",
    "print(clfr.score(x_test,y_test))\n",
    "\n",
    "\n",
    "#USING Logistic Regression\n",
    "\n",
    "\n",
    "print('USING Logistic Regression')\n",
    "regl=sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "regl.fit(x_train,y_train)\n",
    "print(regl.score(x_test,y_test))\n",
    "\n",
    "#USING Naive Bayes\n",
    "\n",
    "print('USING naive Bayes')\n",
    "model=sklearn.naive_bayes.GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "\n",
    "\n",
    "#USING SVM\n",
    "\n",
    "print('Using SVM')\n",
    "modelsvm=sklearn.svm.SVC(kernel='poly')\n",
    "modelsvm.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
